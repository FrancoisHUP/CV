### Directory Structure ###
Directory structure:
└── francoishup-tp2_inf889g/
    ├── README.md
    ├── devoir2.ipynb
    ├── harris_image.py
    ├── panorama_image.py
    └── data/


### Code Content ###
================================================
File: README.md
================================================
# TP2_INF889G

================================================
File: harris_image.py
================================================
import numpy as np
from scipy.ndimage import gaussian_filter, sobel

def describe_point(im: np.ndarray, pos: list) -> dict:
    """Crée un descripteur de caractéristique pour un point l'image
    Parameters
    ----------
    im: ndarray
        Image source
    pos: (2,) list
        Position (r,c) dans l'image qu'on souhaite décrire
    Returns
    -------
    d: dict
        Descripteur pour cet indice.
    """
    r = 2 # Rayon du voisinage
    
    # Descripteur
    d = dict()
    d["pos"] = pos
    d["n"] = (2*r + 1)**2*im.shape[2] # Nombre de valeurs dans le descripteur
    d["data"] = np.zeros((d["n"],), dtype=float)

    # Valeur du pixel central
    cval = im[pos[0], pos[1], :]

    # Limite du voisinage
    r0 = pos[0] - r if pos[0] - r > 0 else 0
    r1 = pos[0] + r + 1 if pos[0] + r + 1 < im.shape[0] else im.shape[0]-1
    c0 = pos[1] - r if pos[1] - r > 0 else 0
    c1 = pos[1] + r + 1 if pos[1] + r + 1 < im.shape[1] else im.shape[1]-1

    # Extraction et normalisation des valeurs
    values = (im[r0:r1, c0:c1, :].astype(float) - cval).ravel()

    # Intégration dans le descripteur
    d['data'][0:len(values)] = values

    return d

def mark_spot(im: np.ndarray, p: list, color: list = [255,0,255]) -> np.ndarray:
    """ Marque la position d'un point dans l'image.
    Parameters
    ----------
    im: ndarray
        Image à marquer
    p: (2,) list
        Position (r,c) du point
    color: (3,) list
        Couleur de la marque
    Returns
    -------
    im: ndarray
        Image marquée.
    """
    r = p[0]
    c = p[1]

    for i in range(-9,10):
        if r+i < 0 or r+i >= im.shape[0] or c+i < 0 or c+i >= im.shape[1]:
            continue # ce pixel est à l'extérieur de l'image
        im[r+i, c, 0] = color[0]
        im[r+i, c, 1] = color[1]
        im[r+i, c, 2] = color[2]
        im[r, c+i, 0] = color[0]
        im[r, c+i, 1] = color[1]
        im[r, c+i, 2] = color[2]

    return im

def mark_corners(im: np.ndarray, d: list, n: int) -> np.ndarray:
    """ Marks corners denoted by an array of descriptors.
    Parameters
    ----------
    im: ndarray
        Image à marquer
    d: list
        Coins dans l'image
    n: int
        Nombre de descripteurs à marquer
    Returns
    -------
    im: ndarray
        Image marquée
    """
    m = np.copy(im)
    for i in range(n):
        m = mark_spot(m, d[i]['pos'])
    return m

def smooth_image(im: np.ndarray, sigma: float) -> np.ndarray:
    """Lissage d'une image avec un filtre gaussien.
    Parameters
    ----------
    im: ndarray
        Image à traiter
    sigma: float
        Écart-type pour la gaussienne.
    Returns
    -------
    s: ndarray
        Image lissée
    """
    s = gaussian_filter(im, sigma)
    return s

def structure_matrix(im: np.ndarray, sigma: float) -> np.ndarray:
    """Calcul du tenseur de structure d'un image.
    Parameters
    ----------
    im: ndarray
        Image à traiter (tons de gris et normalisée entre 0 et 1).
    sigma: float
        Écart-type pour la somme pondérée
    Returns
    -------
    S: ndarray
        Tenseur de structure. 1er canal est Ix^2, 2e canal est Iy^2
        le 3e canal est IxIy
    """
    # Calcul des dérivées
    Ix = sobel(im, axis=1)
    Iy = sobel(im, axis=0)

    # Lissage des dérivées
    Ix2 = smooth_image(Ix**2, sigma)
    Iy2 = smooth_image(Iy**2, sigma)
    IxIy = smooth_image(Ix*Iy, sigma)

    # Création du tenseur de structure
    S = np.zeros((*im.shape,3))
    S[:,:,0] = Ix2
    S[:,:,1] = Iy2
    S[:,:,2] = IxIy

    return S

def cornerness_response(S: np.ndarray) -> np.ndarray:
    """Estimation du cornerness de chaque pixel avec le tenseur de structure S.
    Parameters
    ----------
    S: ndarray
        Tenseur de structure de l'image
    Returns
    -------
    R: ndarray
        Une carte de réponse de la cornerness
    """
    Sxx = S[:,:,0]
    Syy = S[:,:,1]
    Sxy = S[:,:,2]
    
    # Corner response
    det = (Sxx * Syy) - (Sxy**2)
    trace = Sxx + Syy
    alpha=0.06
    
    # On utilise la formulation det(S) - alpha * trace(S)^2, alpha = 0.06
    R = det - alpha *(trace**2)

    return R

def nms_image(im: np.ndarray, w: int) -> np.ndarray:
    """Effectue la supression des non-maximum sur l'image des feature responses.
    Parameters
    ----------
    im: ndarray
        Image 1 canal des réponses de caractéristiques (feature response)
    w: int
        Distance à inspecter pour une grande réponse
    Returns
    -------
    r: ndarray
        Image contenant seulement les maximums locaux pour un voisinage de w pixels.
    """
    r = np.copy(im)
    h, w_ = im.shape

    for i in range(h):
        for j in range(w_):
            max_val = im[i, j]  # On commence par supposer que le pixel actuel est le maximum
            for ki in range(max(0, i-w), min(i+w+1, h)):  # Parcours des voisins en hauteur
                for kj in range(max(0, j-w), min(j+w+1, w_)):  # Parcours des voisins en largeur
                    if im[ki, kj] > max_val:  # Si un voisin a une réponse supérieure
                        r[i, j] = -np.inf  # Le pixel actuel n'est pas un maximum local
                        break  # Pas besoin de chercher plus loin pour ce pixel
                if r[i, j] == -np.inf:
                    break  # Sortie anticipée si le pixel a déjà été marqué

    return r 

def harris_corner_detector(im: np.ndarray, sigma: float, thresh: float, nms: int) -> np.ndarray:
    """ Détecteur de coin de Harris, et extraction des caractéristiques autour des coins.
    Parameters
    ----------
    im: ndarray
        Image à traiter (RGB).
    sigma: float
        Écart-type pour Harris.
    thresh: float
        Seuil pour le cornerness
    nms: int
        Distance maximale à considérer pour la supression des non-maximums
    Returns
    -------
    d: list
        Liste des descripteurs pour chaque coin dans l'image
    """
    img = im.mean(axis=2) # Convert to grayscale
    img = (img.astype(float) - img.min()) / (img.max() - img.min())
    # Calculate structure matrix
    S = structure_matrix(img, sigma)

    # Estimate cornerness
    R = cornerness_response(S)

    # Run NMS on the responses
    Rnms = nms_image(R, nms)

    corner_coordinates = np.where(Rnms > thresh)
    corner_coordinates = list(zip(corner_coordinates[0], corner_coordinates[1]))

    d = []
    for c in corner_coordinates:
        d.append(describe_point(im, c))
    
    return d

def detect_and_draw_corners(im: np.ndarray, sigma: float, thresh: float, nms: int) -> np.ndarray:
    """ Trouve et dessine les coins d'une image
    Parameters
    ----------
    im: ndarray
        L'image à traiter (RGB).
    sigma: float
        Écart-type pour Harris.
    thresh: float
        Seuil pour le cornerness.
    nms: int
        Distance maximale à considérer pour la supression des non-maximums
    Returns
    m: ndarray
        Image marqué avec les coins détectés
    """
    d = harris_corner_detector(im, sigma, thresh, nms)
    m = mark_corners(im, d, len(d))
    return m

================================================
File: panorama_image.py
================================================
from harris_image import harris_corner_detector, mark_corners
import numpy as np
from numpy.linalg import det

def make_translation_homography(dr: float, dc: float) -> np.ndarray:
    """Create a translation homography
    Parameters
    ----------
    dr: float
        Translation along the row axis
    dc: float
        Translation along the column axis
    Returns
    -------
    H: np.ndarray
        Homography as a 3x3 matrix
    """
    H = np.zeros((3,3))
    H[0,0] = 1
    H[1,1] = 1
    H[2,2] = 1
    H[0,2] = dr # Row translation
    H[1,2] = dc # Col translation

def match_compare(a: float, b: float) -> int:
    """ Comparator for matches
    Parameters
    ----------
    a,b : float
        distance for each match to compare.
    Returns
    -------
    result of comparison, 0 if same, 1 if a > b, -1 if a < b.
    """
    comparison = 0
    if a < b:
        comparison = -1
    elif a > b:
        comparison = 1
    else:
        comparison = 0
    return comparison

def both_images(a: np.ndarray, b: np.ndarray) -> np.ndarray:
    """ Place two images side by side on canvas, for drawing matching pixels.
    Parameters
    ----------
    a,b: ndarray
        Images to place
    Returns
    -------
    c: ndarray
        image with both a and b side-by-side.
    """
    width = a.shape[1] + b.shape[1]
    height = a.shape[0] if a.shape[0] > b.shape[0] else b.shape[0]
    channel = a.shape[2] if a.shape[2] > b.shape[2] else b.shape[2]
    
    both = np.zeros((height,width,channel), dtype=a.dtype)
    both[0:a.shape[0], 0:a.shape[1],0:a.shape[2]] = a
    both[0:b.shape[0], a.shape[1]:a.shape[1]+b.shape[1],0:b.shape[2]] = b
    
    return both

def draw_matches(a: np.ndarray, b: np.ndarray, matches: list, inliers: int) -> np.ndarray:
    """Draws lines between matching pixels in two images.
    Parameters
    ----------
    a, b: ndarray
        two images that have matches.
    matches: list
        array of matches between a and b.
    inliers: int
        number of inliers at beginning of matches, drawn in green.
    Returns
    -------
    c: ndarray
        image with matches drawn between a and b on same canvas.
    """
    both = both_images(a, b)
    n = len(matches)
    for i in range(n):
        r1 = matches[i]['p'][0] # Coordonnée y du point p
        r2 = matches[i]['q'][0] # Coordonnée y du point q
        c1 = matches[i]['p'][1] # Coordonnée x du point p
        c2 = matches[i]['q'][1] # Coordonnée x du point q
        for c in range(c1, c2 + a.shape[1]):
            r = int((c-c1)/(c2 + a.shape[1] - c1)*(r2 - r1) + r1)
            both[r, c, 0] = (0 if i<inliers else 255)
            both[r, c, 1] = (255 if i<inliers else 0)
            both[r, c, 2] = 0
    return both

def draw_inliers(a: np.ndarray, b: np.ndarray, H: np.ndarray, matches: list, thresh: float) -> np.ndarray:
    """ Draw the matches with inliers in green between two images.
    Parameters
    ----------
    a, b: ndarray
        two images to match.
    H: ndarray
        Homography matrix
    matches: list
        array of matches between a and b
    thresh: float
        Threshold to define inliers
    Returns
    -------
    lines: ndarray
        Modified images with inliers
    """
    n_inliers, new_matches = model_inliers(H, matches, thresh)
    lines = draw_matches(a, b, new_matches, n_inliers)
    return lines


def find_and_draw_matches(a: np.ndarray, b: np.ndarray, sigma: float=2, thresh: float=3, nms: int=3) -> np.ndarray:
    """ Find corners, match them, and draw them between two images.
    Parameters
    ----------
    a, b: np.ndarray
         images to match.
    sigma: float
        gaussian for harris corner detector. Typical: 2
    thresh: float
        threshold for corner/no corner. Typical: 1-5
    nms: int
        window to perform nms on. Typical: 3
    Returns
    -------
    lines: np.ndarray
        Images with inliers
    """
    ad = harris_corner_detector(a, sigma, thresh, nms)
    bd = harris_corner_detector(b, sigma, thresh, nms)
    m = match_descriptors(ad, bd)

    a = mark_corners(a, ad, len(ad))
    b = mark_corners(b, bd, len(bd))
    lines = draw_matches(a, b, m, 0)

    return lines

def l1_distance(a: np.ndarray, b: np.ndarray) -> float:
    """Calculates L1 distance between to floating point arrays.
    Parameters
    ----------
    a, b: list or np.ndarray
        arrays to compare.
    Returns
    -------
    l1: float
        l1 distance between arrays (sum of absolute differences).
    """
    return np.sum(np.abs(a - b))


def match_descriptors(a: list, b: list) -> list:
    """Finds best matches between descriptors of two images.
    Parameters
    ----------
    a, b: list
        array of descriptors for pixels in two images.
    Returns
    -------
    matches: list
        best matches found. each descriptor in a should match with at most
        one other descriptor in b.
    """
    an = len(a)
    bn = len(b)
    matches = []
    for j in range(an):
        
        # record ai as the index in a and bi as the index in b.
        min_distance = float('inf')
        bind = 0  
        for i in range(bn):
            distance = l1_distance(a[j]["data"], b[i]["data"]) 
            if distance < min_distance:
                min_distance = distance
                bind = i

        matches.append({})
        matches[j]['ai'] = j
        matches[j]['bi'] = bind 
        matches[j]['p'] = a[j]['pos']
        matches[j]['q'] = b[bind]['pos']
        matches[j]['distance'] = min_distance 

    # Sorting matches based on distance to bring the best matches to the front
    matches.sort(key=lambda x: x['distance']) # Or use match_compare function

    # Ensure matches are one-to-one
    seen_b_indices = set()
    filtered_matches = []
    for match in matches:
        if match['bi'] not in seen_b_indices:
            filtered_matches.append(match)
            seen_b_indices.add(match['bi'])

    # print(filtered_matches)
    return filtered_matches

def project_point(H, p):
    """ Apply a projective transformation to a point.
    Parameters
    ----------
    H: np.ndarray
        homography to project point, of shape 3x3
    p: list
        point to project.
    Returns
    -------
    q: list
        point projected using the homography.
    """
    c = np.zeros((3, 1))

    # Convert point p to homogeneous coordinates
    p_homogeneous = np.array([p[0], p[1], 1])
    
    # Apply homography H to p
    c = H @ p_homogeneous
    
    # Convert back to Cartesian coordinates by dividing by the third component
    q = [c[0] / c[2], c[1] / c[2]]

    return q

def point_distance(p, q):
    """Calculate L2 distance between two points.
    Parameters
    ----------
    p, q: list
        Points.
    Returns
    -------
    l2: float
        L2 distance between them.
    """
    l2 = np.sqrt((p[0]-q[0])**2 + (p[1]-q[1])**2)
    return l2

def model_inliers(H: np.ndarray, matches: list, inlier_thresh: float) -> tuple:
    """Count number of inliers in a set of matches. Should also bring inliers to the front of the array.
    Parameters
    ----------
    H: np.ndarray
        homography between coordinate systems.
    matches: list
        matches to compute inlier/outlier.
    thresh: float
        threshold to be an inlier.
    Returns
    -------
    count: int
        number of inliers whose projected point falls within thresh of their match in the other image.
    matches: list
        Should also rearrange matches so that the inliers are first in the array. For drawing.
    """
    inliers = []
    outliers = []
    for match in matches:
        # Extract point p from match and convert to homogeneous coordinates (x, y, 1)
        p = np.array([match['p'][0], match['p'][1], 1])
        q = np.array(match['q'])  # Point q in the match
        
        # Project p using the homography H
        p_proj = project_point(H, p)

        # Calculate L2 distance between projected point and q
        l2_distance = point_distance(p_proj, q[:2])  
        # Check if the match is an inlier based on the threshold
        if l2_distance < inlier_thresh:
            inliers.append(match)
        else:
            outliers.append(match)
    
    # Count of inliers
    count = len(inliers)
    
    # Rearrange matches so inliers are at the beginning
    new_matches = inliers + outliers

    return (count, new_matches)

def randomize_matches(matches: list) -> list:
    """ Randomly shuffle matches for RANSAC.
    Parameters
    ----------
    matches: list
        matches to shuffle in place
    Returns
    -------
    shuffled_matches: list
        Shuffled matches
    """
    for i in range(len(matches) - 1, 1, -1):
        j = np.random.randint(0, i)
        matches[i], matches[j] = matches[j], matches[i]
    return matches

def compute_homography(matches: list, n: int) -> np.ndarray:
    """Computes homography between two images given matching pixels.
    Parameters
    ----------
    matches: list
        matching points between images.
    n: int
        number of matches to use in calculating homography.
    Returns
    -------
    H: np.ndarray
        matrix representing homography H that maps image a to image b.
    """
    assert n >= 4, "Underdetermined, use n>=4"

    M = np.zeros((n*2,8))
    b = np.zeros((n*2,1))

    for i in range(n):
        mx = float(matches[i]['p'][0])
        my = float(matches[i]['p'][1])
        nx = float(matches[i]['q'][0])
        ny = float(matches[i]['q'][1])
        # Fill in the matrices M and b.
        M[2*i] = [mx,  my, 1, 0, 0, 0, -mx*nx, -my*nx]
        M[2*i + 1] = [0, 0, 0, mx,  my, 1, -mx*nx, -my*nx]
        b[2*i] = nx
        b[2*i + 1] = ny

    # Solve the linear system
    if M.shape[0] == M.shape[1] and det(M) != 0 : # TODO Check why it dosent work without 'and det(M) != 0'  
        a = np.linalg.solve(M, b)
    else: # Over-determined, using least-squared
        a = np.linalg.lstsq(M,b,rcond=None)
        a = a[0]
    # If a solution can't be found, return empty matrix;
    if a is None:
        return None
    
    # Fill in the homography H based on the result in a.
    H = np.array([
        [a[0][0], a[1][0], a[2][0]],
        [a[3][0], a[4][0], a[5][0]],
        [a[6][0], a[7][0], 1]
    ])

    return H

def RANSAC(matches: list, thresh: float, k: int, cutoff: int):
    """Perform RANdom SAmple Consensus to calculate homography for noisy matches.
    Parameters
    ----------
    matches: list
        set of matches.
    thresh: float
        inlier/outlier distance threshold.
    k: int
        number of iterations to run.
    cutoff: int
        inlier cutoff to exit early.
    Returns
    -------
    Hb: np.ndarray
        matrix representing most common homography between matches.
    """
    best = 0
    Hb = make_translation_homography(0, 256) # Initial condition
    for k in range(k): # for k iterations:
        suffle = randomize_matches(matches) # shuffle the matches
        H = compute_homography(suffle, 10) # compute a homography with a few matches (how many??)
        inlier_count, _ = model_inliers(H, matches, thresh)
        if inlier_count > best: # if new homography is better than old (how can you tell?):
            best = inlier_count # remember it and how good it is
            Hb = H  # compute updated homography using all inliers

            if inlier_count > cutoff: # if it's better than the cutoff:
                break   # return it immediately

    return Hb  # if we get to the end return the best homography

def combine_images(a, b, H):
    """ Stitches two images together using a projective transformation.
    Parameters
    ----------
    a, b: ndarray
        Images to stitch.
    H: ndarray
        Homography from image a coordinates to image b coordinates.
    Returns
    -------
    c: ndarray
        combined image stitched together.
    """
    Hinv = np.linalg.inv(H)

    # Project the corners of image b into image a coordinates.
    c1 = project_point(Hinv, [0, 0])
    c2 = project_point(Hinv, [b.shape[0], 0])
    c3 = project_point(Hinv, [0, b.shape[1]])
    c4 = project_point(Hinv, [b.shape[0], b.shape[1]])

    # Find top left and bottom right corners of image b warped into image a.
    topleft = [0,0]
    botright = [0,0]
    botright[0] = int(max([c1[0], c2[0], c3[0], c4[0]]))
    botright[1] = int(max([c1[1], c2[1], c3[1], c4[1]]))
    topleft[0]  = int(min([c1[0], c2[0], c3[0], c4[0]]))
    topleft[1]  = int(min([c1[1], c2[1], c3[1], c4[1]]))

    # Find how big our new image should be and the offsets from image a.
    dr = int(min(0, topleft[0]))
    dc = int(min(0, topleft[1]))
    h = int(max(a.shape[0], botright[0]) - dr)
    w = int(max(a.shape[1], botright[1]) - dc)

    # Can disable this if you are making very big panoramas.
    # Usually this means there was an error in calculating H.
    if w > 7000 or h > 7000:
        print("Output too big, stopping.")
        return np.copy(a)

    c = np.zeros((h, w, a.shape[2]), dtype=a.dtype)

    # Paste image a into the new image offset by dr and dc.
    for k in range(a.shape[2]):
        for j in range(a.shape[1]):
            for i in range(a.shape[0]):
                #Remplir l'image
                c[i - dr, j - dc, k] = a[i, j, k]

    # Paste image b using bilinear interpolation.
    for k in range(b.shape[2]):
        for j in range(w):
            for i in range(h):
                # Projection des points en coords d'image b
                p_a = project_point(H, [i + dr, j + dc])

                if 0 <= p_a[0] < b.shape[0] - 1 and 0 <= p_a[1] < b.shape[1] - 1:
                    # Bilinear interpolation
                    i_a, j_a = int(p_a[0]), int(p_a[1])
                    a_1, b_1 = p_a[0] - i_a, p_a[1] - j_a

                    # Interpolate pixel values
                    c[i, j, k] = (1 - a_1) * (1 - b_1) * b[i_a, j_a, k] + \
                                 a_1 * (1 - b_1) * b[i_a + 1, j_a, k] + \
                                 (1 - a_1) * b_1 * b[i_a, j_a + 1, k] + \
                                 a_1 * b_1 * b[i_a + 1, j_a + 1, k]

    return c
def panorama_image(a, b, sigma=2, thresh=0.0003, nms=3, inlier_thresh=5, iters=5000, cutoff=100):
    """ Create a panoramam between two images.
    Parameters
    ----------
    a, b: ndarray
        images to stitch together.
    sigma: float
        gaussian for harris corner detector. Typical: 2
    thresh: float
        threshold for corner/no corner. Typical: 0.0001-0.0005
    nms: int
        window to perform nms on. Typical: 3
    inlier_thresh: float
        threshold for RANSAC inliers. Typical: 2-5
    iters: int
        number of RANSAC iterations. Typical: 1,000-50,000
    cutoff: int
        RANSAC inlier cutoff. Typical: 10-100
    """
    # Calculate corners and descriptors
    ad = harris_corner_detector(a, sigma, thresh, nms)
    bd = harris_corner_detector(b, sigma, thresh, nms)

    # Find matches
    m = match_descriptors(ad, bd)
    
    # Run RANSAC to find the homography
    H = RANSAC(m, inlier_thresh, iters, cutoff)

    # Stitch the images together with the homography
    comb = combine_images(a, b, H)
    return comb


